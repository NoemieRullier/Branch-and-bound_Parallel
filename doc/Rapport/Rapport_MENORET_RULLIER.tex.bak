%% Classe du document
\documentclass[a4paper,10pt]{article}

%% Francisation
\usepackage[francais]{babel} % Indique que l'on utilise le francais
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc} % Indique que l'on utilise tout le clavier
%\usepackage[latin1]{inputenc}

%% Réglages généraux
\usepackage[top=3cm, bottom=3cm, left=3cm, right=3cm]{geometry} % Taille de la feuille
\usepackage{lastpage}

%% Package pour le texte
\usepackage{soul} % Souligner
\usepackage{color} % Utilisation de couleurs
\usepackage{hyperref} % Créer des liens et des signets
\usepackage{eurosym}% Pour le symbole euro
\usepackage{fancyhdr}% Entête et pied de page

%% Package pour les tableaux
\usepackage{multirow} % Colonnes multiples
\usepackage{cellspace}
\usepackage{array}

%% Package pour les dessins
\usepackage{pstricks}
\usepackage{graphicx} % Importer des images
\usepackage{pdftricks} % Pour utiliser avec pdfTex
\usepackage{pst-pdf} % Pour utiliser avec pdfTex
\usepackage{pst-node} % Pose de noeuds
\usepackage{subfig}
\usepackage{float}

%% Package pour les maths
\usepackage{amsmath} % Commandes essentielles
\usepackage{amssymb} % Principaux symboles

%% Package pour le code
\usepackage{listings} % Utilisation de la couleur syntaxique des langages
\usepackage{url}


\usepackage[babel=true]{csquotes} % Permet les quotations (guillemets)
\usepackage{tocvsec2}
\usepackage{amsthm}
\usepackage{amsfonts}

\usepackage{tikz}
\usepackage{pdfpages}

\usetikzlibrary{shapes} % A revoir

%--------------------- Autres définitions ---------------------%

% Propriété des liens
\hypersetup{
colorlinks = true, % Colorise les liens
urlcolor = blue, % Couleur des hyperliens
linkcolor = black, % Couleur des liens internes
}

\definecolor{grey}{rgb}{0.95,0.95,0.95}

% Language Definitions for Turtle
%TODO: a revoir avec les couleur de gedit
\definecolor{olivegreen}{rgb}{0.2,0.8,0.5}
\definecolor{grey2}{rgb}{0.5,0.5,0.5}
\lstdefinelanguage{ttl}{
sensitive=true,
morecomment=[s][\color{grey2}]{@}{:},
morecomment=[l][\color{olivegreen}]{\#},
morecomment=[s][\color{red}]{<}{/>},
morestring=[s][\color{olivegreen}]{<http://w}{\#>},
morestring=[b][\color{blue}]{\"},
}

\lstset{
frame=single,
breaklines=true,
basicstyle=\ttfamily,
backgroundcolor=\color{grey},
basicstyle=\scriptsize,
keywordstyle=\color{blue},
commentstyle=\color{green},
stringstyle=\color{red},
identifierstyle=\color{blue}
}

%Definition de la commande pour retirer l'espace devant les ':'
\makeatletter
\@ifpackageloaded{babel}%
        {\newcommand{\nospace}[1]{{\NoAutoSpaceBeforeFDP{}#1}}}%  % !! double {{}} pour cantonner l'effet à l'argument #1 !!
        {\newcommand{\nospace}[1]{#1}}
\makeatother

\setcounter{tocdepth}{3}
%\maxsecnumdepth{subsubsection} % Dernière section numérotée

\newcommand{\paperPrototyping}{\emph{paper prototyping}}

% Corps du document :
\begin{document}

% Définition des entêtes et pieds de page
\fancyhead[LE,CE,RE,LO,CO,RO]{}
\fancyfoot[LE,CE,RE,LO,CO,RO]{}
\fancyhead[LO, LE]{Multicore programming}
\fancyhead[RO,RE]{2012/2013}
\fancyfoot[LO,LE]{Université de \scshape{Nantes}}
\fancyfoot[RO,RE]{Page \thepage \ sur \pageref{LastPage}}
\renewcommand{\headrulewidth}{0.4pt}
\renewcommand{\footrulewidth}{0.4pt}

%\maketitle
\begin{titlepage}

\vspace*{\fill}~
\begin{center}
{\large \textsc{Rapport de Projet}} \\
\vspace{1cm}
{\LARGE Branch and bound Parallel} \\
\vspace{1cm}
MENORET Clément, RULLIER Noémie \\
\today
\end{center}
\vspace*{\fill}

\vspace{\stretch{1}}
\begin{center}
\noindent 
\includegraphics[height=2.5cm]{Images/universite.png}
\end{center}
\pagebreak
\end{titlepage}

\newpage
\tableofcontents 

% Introduction
\newpage
\pagestyle{fancy}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%  Introduction générale
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Introduction}
L'objectif de ce projet fut de paralléliser l'algorithme \emph{branch and bound} permettant de calculer le minimum d'une fonction réelle par le découpage en boites de domaine.

Nous allons donc ici présenter les différentes décisions prises afin de paralléliser l'algorithme à l'aide des technologies \emph{MPI} et \emph{OpenMP}, ainsi qu'une comparaison des résultats obtenus entre la version parallèle et séquentielle. 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%  Etape 1
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newpage
\section{Les étapes de parallélisation}

Afin de paralléliser ce programme, nous avons utilisé MPI et OpenMP. Ils permettent respectivement d'exploiter des ordinateurs distants, afin d'exécuter des portions de programme et de traiter les données, sur une architecture à mémoire partagée. 

\subsection{MPI}
Nous avons ici décidé d'utiliser quatre ordinateurs grâce à MPI. Nous avons donc, dans un premier temps, regroupé toutes les machines dans le même \emph{Communicator} et initialisé le tout. A ce stade, les quatre ordinateurs vont exécuter la suite de la fonction main. Nous avons donc précisé que seul l'ordinateur de rang 0 exécute le premier appel à \emph{minimize\_first}. 

Cette première fonction permet de faire un premier découpage en quatre intervalles. Chaque machine recevra ensuite l'ensemble des informations permettant d'exécuter à leur tour la fonction \emph{minimize}; chaque machine l'exécutera pour un des quatre intervalles. Ces informations seront envoyées via la fonction \emph{MPI\_Send()}. Elle permet d'envoyer des données à un ordinateur en lui précisant son rang. Afin de lui envoyer toutes les données nécessaires, nous avons créé de nouvelles structures : 
\begin{itemize}
\item \textbf{interv}: cette structure permet de stocker l'intervalle qui va être envoyé. Elle est composée des attributs \emph{x} et \emph{y} de type \emph{interval} ; 
\item \textbf{consts}: cette structure permet de stocker l'ensemble des paramètres nécessaires à la fonction \emph{minimize} ; 
\item \textbf{package}: cette structure permet d'envoyer à la fois l'intervalle et les autres paramètres. Elle est composée d'un attribut \emph{inter} de type \emph{interv} et d'un attribut \emph{constantes} de type \emph{consts}. 
\end{itemize}
Nous avons décidé de créer deux structures distinctes car pour chaque machine, l'ensemble des paramètres, autre que l'intervalle, sont identiques.
Afin que notre structure soit bien envoyée via la fonction \emph{MPI\_Send()}, nous avons défini le type de données à envoyer comme étant des \emph{MPI\_BYTE}.

Nous avons donc, dans la suite de la fonction main, fait appel à la fonction \emph{MPI\_Recv()}. Celle-ci permet aux différentes machines de recevoir les messages envoyés par la machine de rang $i$ (ici $i=0$). Ces machines vont ensuite exécuter la fonction \emph{minimize}. 

De plus, dans le but de récupérer le minimum final, nous avons ajouté la fonction \emph{MPI\_Reduce()}. Celle-ci nous permettra de trouver le minimum de tous les minimums calculés par chaque machine et de la stocker dans \emph{min\_global}.
Nous devons aussi récupérer la liste des intervalles dans lesquels un minimum a été trouvé. Pour cela, nous avons pour toutes les machines (autres que celle de rang 0) envoyé à la machine 0, leur tableau contenant les minimums. La machine de rang 0, va recevoir ce tableau et ajouter les éléments de celui-ci à sa propre liste de minimums. Elle doit cependant créer un tableau de la taille du tableau qu'elle va recevoir; or elle ne la connait pas. Pour cela, nous utilisons \emph{MPI\_Probe()} qui permet d'initialiser un \emph{MPI\_Status} et de récupérer sa taille via un \emph{MPI\_Get\_Count()}.

\subsection{OpenMP}
Nous avons ajouté un niveau supplémentaire de parallélisation avec l'ajout d'OpenMP. En effet, sur chaque machine traitant une instance de \emph{minimize} nous avons parallélisé les appels récursifs à la fonction \emph{minimize}. 
Nous avons donc défini quatre sections (\emph{\#pragma omp section}), une pour chaque appel à \emph{minimize}. Nous avons choisi des sections plutôt que des tâches car elles permettent d'avoir une barrière à la fin de leur exécution. 

%TODO A modifier quand ça marchera
Nous avons, de plus, ajouté une réduction sur le minimum obtenu dans toutes ces exécutions (\emph{\#pragma omp parallel sections reduction (min:min\_ub)}).


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%  Etape 2
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newpage
\section{Les résultats}
Afin d'effectuer nos tests, nous avons choisi d'utiliser tous les algorithmes proposés avec des précisions différentes.

\subsection{MPI}
%TODO Clément: faire texte comparaison

Suite à notre étude comparative des deux versions des programmes, séquentiels et parallélisés, on remarque que les résultats obtenus avec la version parallélisée sont identiques aux résultats obtenus avec la version séquentielle. 
Cependant, le fait d'utiliser MPI de manière virtuelle sur une seule machine physique provoque un ralentissement de l'exécution de l'algorithme du aux nombreux traitements à réaliser pour la simulation du comportement de MPI et les modifications apportées à l'algorithme en terme d'envoi et de réception des données. Entre différentes machines physiques, la charge de travail serait répartie. \\

Les résultats détaillés de notre benchmark sont donnés dans les tableaux suivants : \\

Cette comparaison a été faite pour la précision \emph{0,01}.

\begin{tabular}{|c|c|c|c|}
\hline
\multicolumn{4}{|c|}{Sequential version}\\
\hline
Algorithm & Number of minimizers & Upper bound for minimum & Time (s) \\
\hline
goldstein\_price & 16889 & 9.153558944677261 & 5.080\\
\hline
beale & 2209 & 0.001346965117212209 & 2.976\\
\hline
three\_hump\_camel & 154 & 0.1145362854871269 & 4.316\\
\hline
booth & 225 & 0.0008430480957031254 & 5.348\\
\hline
\end{tabular}

\begin{tabular}{|c|c|c|c|}
\hline
\multicolumn{4}{|c|}{Parallel version with MPI}\\
\hline
Algorithm & Number of minimizers & Upper bound for minimum & Time (s) \\
\hline
goldstein\_price & 14989 & 9.153558944677261 & 0.512\\
\hline
beale & 83 & 0.001346965117212209 & 0.044\\
\hline
three\_hump\_camel & 152 & 0.1145362854871269 & 0.116\\
\hline
booth & 23 & 0.0008430480957031254 & 0.040\\
\hline
\end{tabular}

Cette comparaison a été faite pour la précision \emph{0,005}.

\begin{tabular}{|c|c|c|c|}
\hline
\multicolumn{4}{|c|}{Sequential version}\\
\hline
Algorithm & Number of minimizers & Upper bound for minimum & Time (s) \\
\hline
goldstein\_price & 29237 & 6.1188468974418 & 1.100\\
\hline
beale & 76 & 0.0002946668823264963 & 0.076\\
\hline
three\_hump\_camel & 152 & 0.02863407135145293 & 0.276\\
\hline
booth & 21 & 0.0001564025878906251 & 0.080\\
\hline
\end{tabular}

\begin{tabular}{|c|c|c|c|}
\hline
\multicolumn{4}{|c|}{Parallel version with MPI}\\
\hline
Algorithm & Number of minimizers & Upper bound for minimum & Time (s) \\
\hline
goldstein\_price & 36163 & 6.1188468974418 & 11.001\\
\hline
beale & 3795 & 0.0002946668823264963 & 4.388\\
\hline
three\_hump\_camel & 154 & 0.02863407135145293 & 4.672\\
\hline
booth & 303 & 0.0001564025878906251 & 3.304\\
\hline
\end{tabular}

Cette comparaison a été faite pour la précision \emph{0,001}.

\begin{tabular}{|c|c|c|c|}
\hline
\multicolumn{4}{|c|}{Sequential version}\\
\hline
Algorithm & Number of minimizers & Upper bound for minimum & Time (s) \\
\hline
goldstein\_price & 18506 & 3.788114240740458 & 2.816\\
\hline
beale & 76 & 4.613139957035884e-06 & 0.576\\
\hline
three\_hump\_camel & 152 & 0.0004474073648452814 & 5.124\\
\hline
booth & 23 & 3.293156623840334e-06 & 0.568\\
\hline
\end{tabular}

\begin{tabular}{|c|c|c|c|}
\hline
\multicolumn{4}{|c|}{Parallel version with MPI}\\
\hline
Algorithm & Number of minimizers & Upper bound for minimum & Time (s) \\
\hline
goldstein\_price & 96767 & 3.788114240740458 & 11.321\\
\hline
beale & 18525 & 4.613139957035884e-06 & 6.112\\
\hline
three\_hump\_camel & 154 & 0.0004474073648452814 & 14.157\\
\hline
booth & 808 & 3.293156623840334e-06 & 4.256\\
\hline
\end{tabular}

\subsection{OpenMP}
%TODO Clément dire queça marche pas donc on a pas de résultats

Nous n'avons malheureusement pas eu le temps de terminer 
l'implémentation de l'algorithme parallèle avec OpenMP, 
nous ne pouvons donc pas fournir de résultats expérimentaux. \\


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%  CONCLUSION GENERALE
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newpage
\section{Conclusion générale}
Ce projet nous a permis de réfléchir à la façon de paralléliser un programme séquentiel tout en s'initiant à la programmation avec MPI et OpenMP. 
Bien que nous ayons regretté de ne pas pouvoir tester ce programme 
sur plusieurs machines physiques, l'utilisation du parallélisme sur ce projet 
reste cruciale à partir du moment où l'on souhaite obtenir un résultat calculé
avec une bonne précision en un minimum de temps sur cet algorithme. 

\end{document}


